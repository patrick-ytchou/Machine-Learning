{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "PATH = 'model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Save all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ytchou/opt/miniconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Method 1 \n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1381,  0.0810,  0.3229, -0.2405, -0.3364, -0.3802]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2255], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Method 2: Save State Dict (Preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1381,  0.0810,  0.3229, -0.2405, -0.3364, -0.3802]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2255], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# model must be created again with parameters\n",
    "loaded_model = Model(n_input_features=6)\n",
    "loaded_model.load_state_dict(torch.load(PATH))\n",
    "loaded_model.eval()\n",
    "\n",
    "for param in loaded_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[-0.1381,  0.0810,  0.3229, -0.2405, -0.3364, -0.3802]])), ('linear.bias', tensor([0.2255]))])\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Saving Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [5000995696, 5000998256]}]}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"epoch\": 90,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optim_state\": optimizer.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [5004515600, 5000962128]}]}\n",
      "\n",
      "OrderedDict([('linear.weight', tensor([[-0.1381,  0.0810,  0.3229, -0.2405, -0.3364, -0.3802]])), ('linear.bias', tensor([0.2255]))])\n"
     ]
    }
   ],
   "source": [
    "# Load back the checkpoing\n",
    "loaded_checkpoint = torch.load(\"checkpoint.pth\")\n",
    "epoch = loaded_checkpoint['epoch']\n",
    "\n",
    "# Initialize a model and an optimizer\n",
    "model = Model(n_input_features=6)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
    "\n",
    "# Load the checkpoint state dict into the model and the optimizer\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optim_state'])\n",
    "\n",
    "print(optimizer.state_dict())\n",
    "print('')\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Saving and Loading on CPU / GPU\n",
    "\n",
    "### Case1: Save on GPU, Load on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = Model(n_input_features=6)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "# map_location: the saved model is originally on GPU. Now mapped to cpu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Case2 : Save on GPU, Load on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "# No map_location is needed here since the model is saved and loaded on the same location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Case3 : Save on CPU, Load on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = Model(n_input_features=6)\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "# Choose whatever GPU number you want\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
