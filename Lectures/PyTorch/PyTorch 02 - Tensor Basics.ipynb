{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4013e-44, 0.0000e+00, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3) # 1D vector with 3 elements\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 1.8754e+28],\n",
      "        [4.1586e-05, 8.4483e+20, 1.0414e-11]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2,3) # 2D vector with 3 elements in each\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1190, 0.6628],\n",
      "        [0.4868, 0.6041]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2) # Random 2D tensor\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,2) # All zeros\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2) # All ones\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2, dtype=torch.int) # You can set the dtype by setting \n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2, dtype=torch.int) # You can set the dtype by setting \n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.5, 0.1]) # Create from a list\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0115, 0.4057],\n",
      "        [0.8638, 0.7622]])\n",
      "tensor([[0.8988, 0.9610],\n",
      "        [0.9968, 0.4154]])\n",
      "tensor([[0.9103, 1.3667],\n",
      "        [1.8606, 1.1777]])\n",
      "tensor([[0.9103, 1.3667],\n",
      "        [1.8606, 1.1777]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "z = x + y # Element-wise addition\n",
    "z = torch.add(x,y) # Same as x + y\n",
    "print(z)\n",
    "\n",
    "y.add_(x) # In-place Addition.  Set y to be x+y\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, every function with a trailing underscore will do a in-place operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8988, -0.9610],\n",
      "        [-0.9968, -0.4154]])\n"
     ]
    }
   ],
   "source": [
    "z = x - y # Note that y here is changed by the in-placde operation above.\n",
    "z = torch.sub(x,y) # Same as x - y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0104, 0.5544],\n",
      "        [1.6071, 0.8977]])\n",
      "tensor([[1.0986, 0.7317],\n",
      "        [0.5375, 0.8491]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.mul(x,y) # Element-wise multiplication z = x * y\n",
    "print(z)\n",
    "\n",
    "y.mul_(x) # y = y * x. Again in-place addition here.\n",
    "\n",
    "z = torch.div(x, y) # Element-wise division. z = x / y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5477, 0.3944, 0.3828],\n",
      "        [0.6426, 0.9040, 0.7911],\n",
      "        [0.6464, 0.2564, 0.3911],\n",
      "        [0.3102, 0.8791, 0.0309],\n",
      "        [0.7390, 0.2088, 0.6210]])\n",
      "\n",
      "tensor([0.6426, 0.9040, 0.7911])\n",
      "\n",
      "tensor(0.9040)\n",
      "0.9040480852127075\n"
     ]
    }
   ],
   "source": [
    "# Slicing Operation\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print('')\n",
    "print(x[1,:])\n",
    "print('')\n",
    "print(x[1,1])\n",
    "print(x[1,1].item()) # If you have only one item in your tensor, you have retrieve the value out with .item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3347, 0.2766, 0.3431, 0.1502],\n",
      "        [0.8926, 0.1400, 0.3400, 0.5738],\n",
      "        [0.6633, 0.1542, 0.8942, 0.5913],\n",
      "        [0.7100, 0.7845, 0.9933, 0.6279]])\n",
      "\n",
      "\n",
      "tensor([0.3347, 0.2766, 0.3431, 0.1502, 0.8926, 0.1400, 0.3400, 0.5738, 0.6633,\n",
      "        0.1542, 0.8942, 0.5913, 0.7100, 0.7845, 0.9933, 0.6279])\n",
      "\n",
      "\n",
      "tensor([[0.3347, 0.2766, 0.3431, 0.1502, 0.8926, 0.1400, 0.3400, 0.5738],\n",
      "        [0.6633, 0.1542, 0.8942, 0.5913, 0.7100, 0.7845, 0.9933, 0.6279]])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "print('\\n')\n",
    "y = x.view(-1) #.view is the same as the .reshape in pandas.\n",
    "print(y)\n",
    "print('\\n')\n",
    "y = y.view(2,-1)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Between Numpy and Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy() # convert to numpy\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you are using the CPU version, the tensor and the converted numpy will share the same memory location. Thus, if we hange one of the variable, the other one will change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print('')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a) # convert to torch\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Similar memory location issue happens here.\n",
    "a += 1\n",
    "print(a)\n",
    "print('')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensor on GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    x = torch.ones(5, device=device) # Create the tensor on GPU \n",
    "    \n",
    "    # Another why to create tensor on GPU\n",
    "    y = torch.ones(5)\n",
    "    y = y.to(device) # Move tensor to GPU from CPU\n",
    "    \n",
    "    z = x * y\n",
    "    # z.numpy() will raise error since numpy can only handle CPU tensor\n",
    "    z = z.to(\"cpu\").numpy() # Move to CPU and then convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True) \n",
    "x \n",
    "# If you want to optimize this variable later, \n",
    "# you need to set requires_grad = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
